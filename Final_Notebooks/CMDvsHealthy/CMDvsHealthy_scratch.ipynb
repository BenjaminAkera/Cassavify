{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: CMD vs Healthy Classifier Using a Deep ConvNet trained from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we train a classifier for Cassava leaves bearing visual symptoms of the Cassava Mosaic Disease vs Healthy leaves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape= (150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "## augmentation configuration we shall use for training\n",
    "\n",
    "train_datagen =ImageDataGenerator(\n",
    "                rescale = 1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size = (150,150),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'data/validation',\n",
    "    target_size = (150,150),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 283s - loss: 0.6738 - acc: 0.6205 - val_loss: 0.6172 - val_acc: 0.6546\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 293s - loss: 0.5706 - acc: 0.7110 - val_loss: 0.6008 - val_acc: 0.6393\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 275s - loss: 0.5244 - acc: 0.7640 - val_loss: 0.5049 - val_acc: 0.7708\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 331s - loss: 0.5066 - acc: 0.7660 - val_loss: 0.5173 - val_acc: 0.7448\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 322s - loss: 0.4572 - acc: 0.8005 - val_loss: 0.4891 - val_acc: 0.7865\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 313s - loss: 0.4526 - acc: 0.8095 - val_loss: 0.4898 - val_acc: 0.7995\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 294s - loss: 0.4243 - acc: 0.8255 - val_loss: 0.5003 - val_acc: 0.7786\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 225s - loss: 0.4238 - acc: 0.8120 - val_loss: 0.4646 - val_acc: 0.7760\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 221s - loss: 0.3881 - acc: 0.8385 - val_loss: 0.8342 - val_acc: 0.6732\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 220s - loss: 0.3657 - acc: 0.8480 - val_loss: 0.4376 - val_acc: 0.8021\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 222s - loss: 0.3617 - acc: 0.8485 - val_loss: 0.4296 - val_acc: 0.8060\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 220s - loss: 0.3445 - acc: 0.8660 - val_loss: 0.8998 - val_acc: 0.6706\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 221s - loss: 0.3060 - acc: 0.8810 - val_loss: 0.5195 - val_acc: 0.7668\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 220s - loss: 0.3248 - acc: 0.8770 - val_loss: 0.4481 - val_acc: 0.7925\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 221s - loss: 0.2890 - acc: 0.8920 - val_loss: 0.5435 - val_acc: 0.7292\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 219s - loss: 0.3024 - acc: 0.8845 - val_loss: 0.6197 - val_acc: 0.7109\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 221s - loss: 0.2898 - acc: 0.8920 - val_loss: 0.5345 - val_acc: 0.7344\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 222s - loss: 0.2791 - acc: 0.8925 - val_loss: 0.7034 - val_acc: 0.7591\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 220s - loss: 0.2868 - acc: 0.8890 - val_loss: 0.6008 - val_acc: 0.7240\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 218s - loss: 0.2705 - acc: 0.8990 - val_loss: 0.5124 - val_acc: 0.7682\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 220s - loss: 0.2829 - acc: 0.8960 - val_loss: 0.8792 - val_acc: 0.6771\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 220s - loss: 0.2569 - acc: 0.9015 - val_loss: 0.5517 - val_acc: 0.7500\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 220s - loss: 0.2678 - acc: 0.9070 - val_loss: 0.5973 - val_acc: 0.6953\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 220s - loss: 0.2474 - acc: 0.9055 - val_loss: 0.5150 - val_acc: 0.7747\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 222s - loss: 0.2530 - acc: 0.9080 - val_loss: 0.4816 - val_acc: 0.7799\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 219s - loss: 0.2664 - acc: 0.9075 - val_loss: 0.5801 - val_acc: 0.7887\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 221s - loss: 0.2322 - acc: 0.9125 - val_loss: 0.7184 - val_acc: 0.7887\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 220s - loss: 0.2739 - acc: 0.9055 - val_loss: 0.7336 - val_acc: 0.6992\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 220s - loss: 0.2518 - acc: 0.9110 - val_loss: 0.4751 - val_acc: 0.7917\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 221s - loss: 0.2402 - acc: 0.9135 - val_loss: 0.7153 - val_acc: 0.7773\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 219s - loss: 0.2619 - acc: 0.9110 - val_loss: 1.1096 - val_acc: 0.7174\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 222s - loss: 0.2741 - acc: 0.9130 - val_loss: 0.5756 - val_acc: 0.7513\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 222s - loss: 0.2379 - acc: 0.9045 - val_loss: 4.2101 - val_acc: 0.5651\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 222s - loss: 0.2396 - acc: 0.9100 - val_loss: 0.6585 - val_acc: 0.7734\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 219s - loss: 0.2847 - acc: 0.9045 - val_loss: 1.1320 - val_acc: 0.6419\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 220s - loss: 0.2813 - acc: 0.9025 - val_loss: 0.5106 - val_acc: 0.7930\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 221s - loss: 0.2613 - acc: 0.9100 - val_loss: 0.6933 - val_acc: 0.7643\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 220s - loss: 0.2476 - acc: 0.9215 - val_loss: 1.0781 - val_acc: 0.6784\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 220s - loss: 0.2891 - acc: 0.9075 - val_loss: 0.5521 - val_acc: 0.7732\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 221s - loss: 0.2380 - acc: 0.9235 - val_loss: 0.8491 - val_acc: 0.7642\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 221s - loss: 0.2932 - acc: 0.8955 - val_loss: 0.8516 - val_acc: 0.7500\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 223s - loss: 0.2874 - acc: 0.9005 - val_loss: 0.7274 - val_acc: 0.7474\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 244s - loss: 0.2913 - acc: 0.9165 - val_loss: 1.0451 - val_acc: 0.7227\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 235s - loss: 0.3106 - acc: 0.9070 - val_loss: 0.5955 - val_acc: 0.7695\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 227s - loss: 0.2583 - acc: 0.9020 - val_loss: 0.8584 - val_acc: 0.7995\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 295s - loss: 0.2896 - acc: 0.8980 - val_loss: 0.7392 - val_acc: 0.7943\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 342s - loss: 0.2984 - acc: 0.9040 - val_loss: 0.8330 - val_acc: 0.7513\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 333s - loss: 0.2599 - acc: 0.9080 - val_loss: 0.8652 - val_acc: 0.7956\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 442s - loss: 0.2985 - acc: 0.9035 - val_loss: 0.6884 - val_acc: 0.7878\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 410s - loss: 0.2705 - acc: 0.9075 - val_loss: 1.0960 - val_acc: 0.7305\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2000 // batch_size,\n",
    "    epochs = 50,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 800 // batch_size)\n",
    "\n",
    "model.save_weights('weights/first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
